{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(text, allowedChars):\n",
    "    label_list = []\n",
    "    for c in text:\n",
    "        onehot = [0] * len(allowedChars)\n",
    "        onehot[allowedChars.index(c)] = 1\n",
    "        label_list.append(onehot)\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_decoding(prediction, allowedChars):\n",
    "    text = ''\n",
    "    for predict in prediction:\n",
    "        value = np.argmax(predict[0])\n",
    "        text += allowedChars[value]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(filename, size):\n",
    "    train_data = []\n",
    "    if os.path.isdir(filename):\n",
    "        train_data = np.stack([np.array(cv2.imread(filename + str(index) + \".jpg\"))/127.5 - 1 for index in range(1, size + 1)])\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_data(filename, allowedChars, num_dic, size):\n",
    "    train_label = []\n",
    "    traincsv = open(filename, 'r', encoding = 'utf8')\n",
    "    \n",
    "    read_label =  [one_hot_encoding(row[0], allowedChars) for row in csv.reader(traincsv)]\n",
    "    read_label =  read_label[:size]\n",
    "    train_label = [[] for _ in range(num_dic)]\n",
    "\n",
    "    for arr in read_label:\n",
    "        for index in range(num_dic):\n",
    "            train_label[index].append(arr[index])\n",
    "    train_label = [arr for arr in np.asarray(train_label)]\n",
    "    return train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history, train, validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "def build_vgg_model(width, height, allowedChars, num_digit):\n",
    "    tensor_in = Input((height, width, 3))\n",
    "\n",
    "    tensor_out = tensor_in\n",
    "    tensor_out = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "    tensor_out = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "    tensor_out = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = BatchNormalization(axis=1)(tensor_out)\n",
    "    tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "    tensor_out = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "    tensor_out = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "    tensor_out = BatchNormalization(axis=1)(tensor_out)\n",
    "    tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "\n",
    "    tensor_out = Flatten()(tensor_out)\n",
    "    tensor_out = Dropout(0.5)(tensor_out)\n",
    "\n",
    "    tensor_out = [Dense(len(allowedChars), name='digit' + str(i), activation='softmax')(tensor_out) for i in range(1, num_digit + 1)]\n",
    "    \n",
    "    model = Model(inputs=tensor_in, outputs=tensor_out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "\n",
    "def build_resnet50_model(size, allowedChars, num_digit):\n",
    "    model = ResNet50(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
    "\n",
    "    tensor_in = model.input\n",
    "    \n",
    "    tensor_out = model.output\n",
    "    tensor_out = Flatten()(tensor_out)\n",
    "    tensor_out = Dropout(0.5)(tensor_out)\n",
    "    outputs = [Dense(len(allowedChars), name='digit' + str(i), activation='softmax')(tensor_out) for i in range(1, num_digit + 1)]\n",
    "\n",
    "    model2 = Model(tensor_in, outputs)\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "    model2.summary()\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "def build_inceptionv3_model(size, allowedChars, num_digit):\n",
    "    model = InceptionV3(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
    "\n",
    "    tensor_in = model.input\n",
    "    \n",
    "    tensor_out = model.output\n",
    "    tensor_out = Flatten()(tensor_out)\n",
    "    tensor_out = Dropout(0.5)(tensor_out)\n",
    "    outputs = [Dense(len(allowedChars), name='digit' + str(i), activation='softmax')(tensor_out) for i in range(1, num_digit + 1)]\n",
    "\n",
    "    model2 = Model(tensor_in, outputs)\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "    model2.summary()\n",
    "    return model2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
