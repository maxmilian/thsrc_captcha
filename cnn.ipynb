{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2, csv\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils  import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "SIZE = 3500\n",
    "MODEL_FOLDER = \"model/\"\n",
    "WIDTH = 140\n",
    "HEIGHT = 48\n",
    "PROCESSED_FOLDER = \"processed/\"\n",
    "LABEL_CSV_FILE = 'label.csv'\n",
    "dic19 = {'2':0, '3':1, '4':2, '5':3, '7':4, '9':5, 'A':6, 'C':7, 'F':8, 'H':9, 'K':10, 'M':11, 'N':12, 'P':13, 'Q':14, 'R':15, 'T':16, 'Y':17, 'Z':18}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onelist(text):\n",
    "    label_list = []\n",
    "    for c in text:\n",
    "        onehot = [0 for _ in range(len(dic19))]\n",
    "        onehot[dic19[c]] = 1\n",
    "        label_list.append(onehot)\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0916 10:01:49.891368 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0916 10:01:49.911611 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0916 10:01:49.919960 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0916 10:01:49.991585 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CNN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 10:01:50.092438 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0916 10:01:50.093451 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0916 10:01:50.543286 4711863744 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#creat CNN model\n",
    "print('Creating CNN model...')\n",
    "tensor_in = Input((HEIGHT, WIDTH, 3))\n",
    "tensor_out = tensor_in\n",
    "tensor_out = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "tensor_out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(tensor_out)\n",
    "tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "tensor_out = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "tensor_out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(tensor_out)\n",
    "tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "tensor_out = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "tensor_out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(tensor_out)\n",
    "tensor_out = BatchNormalization(axis=1)(tensor_out)\n",
    "tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "tensor_out = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "tensor_out = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "tensor_out = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(tensor_out)\n",
    "tensor_out = BatchNormalization(axis=1)(tensor_out)\n",
    "tensor_out = MaxPooling2D(pool_size=(2, 2))(tensor_out)\n",
    "\n",
    "tensor_out = Flatten()(tensor_out)\n",
    "tensor_out = Dropout(0.5)(tensor_out)\n",
    "\n",
    "tensor_out = [Dense(19, name='digit1', activation='softmax')(tensor_out),\\\n",
    "              Dense(19, name='digit2', activation='softmax')(tensor_out),\\\n",
    "              Dense(19, name='digit3', activation='softmax')(tensor_out),\\\n",
    "              Dense(19, name='digit4', activation='softmax')(tensor_out)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 10:01:50.637598 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48, 140, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 48, 140, 32)  896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 46, 138, 32)  9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 23, 69, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 23, 69, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 21, 67, 64)   36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 33, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 33, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 31, 128)   147584      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 31, 128)   32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 15, 128)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 15, 256)   295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 15, 256)   590080      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 2, 7, 256)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 7, 512)    1180160     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2, 7, 512)    8           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 3, 512)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1536)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1536)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "digit1 (Dense)                  (None, 19)           29203       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "digit2 (Dense)                  (None, 19)           29203       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "digit3 (Dense)                  (None, 19)           29203       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "digit4 (Dense)                  (None, 19)           29203       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,469,268\n",
      "Trainable params: 2,469,248\n",
      "Non-trainable params: 20\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=tensor_in, outputs=tensor_out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data...\n",
      "Reading completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading training data...\")\n",
    "\n",
    "train_data = np.stack([np.array(cv2.imread(PROCESSED_FOLDER + str(index) + \".jpg\"))/255.0 for index in range(1, SIZE + 1)])\n",
    "traincsv = open(LABEL_CSV_FILE, 'r', encoding = 'utf8')\n",
    "\n",
    "\n",
    "read_label =  [to_onelist(row[0]) for row in csv.reader(traincsv)]\n",
    "train_label = [[] for _ in range(4)]\n",
    "for arr in read_label:\n",
    "    for index in range(4):\n",
    "        train_label[index].append(arr[index])\n",
    "train_label = [arr for arr in np.asarray(train_label)]\n",
    "\n",
    "print(\"Reading completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = MODEL_FOLDER + \"{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_digit4_acc', verbose=1, save_best_only=False, mode='max')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, mode='auto')\n",
    "tensorBoard = TensorBoard(log_dir = 'logs', histogram_freq = 1)\n",
    "callbacks_list = [tensorBoard, earlystop, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 10:01:58.558650 4711863744 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model(MODEL_FOLDER + \"25-1.10-3.01.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 10:02:01.011471 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/callbacks.py:1120: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "W0916 10:02:01.154010 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0916 10:02:01.158941 4711863744 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2800 samples, validate on 700 samples\n",
      "Epoch 1/10\n",
      "2800/2800 [==============================] - 84s 30ms/step - loss: 0.9477 - digit1_loss: 0.1927 - digit2_loss: 0.2598 - digit3_loss: 0.2288 - digit4_loss: 0.2664 - digit1_acc: 0.9396 - digit2_acc: 0.9196 - digit3_acc: 0.9357 - digit4_acc: 0.9261 - val_loss: 1.0153 - val_digit1_loss: 0.2056 - val_digit2_loss: 0.2861 - val_digit3_loss: 0.2782 - val_digit4_loss: 0.2454 - val_digit1_acc: 0.9443 - val_digit2_acc: 0.9214 - val_digit3_acc: 0.9171 - val_digit4_acc: 0.9286\n",
      "\n",
      "Epoch 00001: saving model to model/01-0.95-1.02.hdf5\n",
      "Epoch 2/10\n",
      "2800/2800 [==============================] - 83s 30ms/step - loss: 0.7699 - digit1_loss: 0.1469 - digit2_loss: 0.2247 - digit3_loss: 0.1835 - digit4_loss: 0.2150 - digit1_acc: 0.9518 - digit2_acc: 0.9336 - digit3_acc: 0.9479 - digit4_acc: 0.9379 - val_loss: 1.0061 - val_digit1_loss: 0.2462 - val_digit2_loss: 0.3055 - val_digit3_loss: 0.2483 - val_digit4_loss: 0.2061 - val_digit1_acc: 0.9371 - val_digit2_acc: 0.9071 - val_digit3_acc: 0.9229 - val_digit4_acc: 0.9343\n",
      "\n",
      "Epoch 00002: saving model to model/02-0.77-1.01.hdf5\n",
      "Epoch 3/10\n",
      "2800/2800 [==============================] - 80s 29ms/step - loss: 0.6483 - digit1_loss: 0.1372 - digit2_loss: 0.1756 - digit3_loss: 0.1516 - digit4_loss: 0.1838 - digit1_acc: 0.9550 - digit2_acc: 0.9439 - digit3_acc: 0.9543 - digit4_acc: 0.9575 - val_loss: 0.8819 - val_digit1_loss: 0.2356 - val_digit2_loss: 0.2327 - val_digit3_loss: 0.2208 - val_digit4_loss: 0.1927 - val_digit1_acc: 0.9386 - val_digit2_acc: 0.9400 - val_digit3_acc: 0.9386 - val_digit4_acc: 0.9386\n",
      "\n",
      "Epoch 00003: saving model to model/03-0.65-0.88.hdf5\n",
      "Epoch 4/10\n",
      "2800/2800 [==============================] - 82s 29ms/step - loss: 0.5693 - digit1_loss: 0.1285 - digit2_loss: 0.1523 - digit3_loss: 0.1248 - digit4_loss: 0.1637 - digit1_acc: 0.9618 - digit2_acc: 0.9564 - digit3_acc: 0.9636 - digit4_acc: 0.9554 - val_loss: 0.9099 - val_digit1_loss: 0.2333 - val_digit2_loss: 0.2553 - val_digit3_loss: 0.2484 - val_digit4_loss: 0.1729 - val_digit1_acc: 0.9386 - val_digit2_acc: 0.9271 - val_digit3_acc: 0.9229 - val_digit4_acc: 0.9400\n",
      "\n",
      "Epoch 00004: saving model to model/04-0.57-0.91.hdf5\n",
      "Epoch 5/10\n",
      "2800/2800 [==============================] - 84s 30ms/step - loss: 0.4602 - digit1_loss: 0.1030 - digit2_loss: 0.1169 - digit3_loss: 0.1097 - digit4_loss: 0.1307 - digit1_acc: 0.9657 - digit2_acc: 0.9614 - digit3_acc: 0.9707 - digit4_acc: 0.9664 - val_loss: 0.8486 - val_digit1_loss: 0.2139 - val_digit2_loss: 0.2361 - val_digit3_loss: 0.2108 - val_digit4_loss: 0.1877 - val_digit1_acc: 0.9543 - val_digit2_acc: 0.9329 - val_digit3_acc: 0.9371 - val_digit4_acc: 0.9429\n",
      "\n",
      "Epoch 00005: saving model to model/05-0.46-0.85.hdf5\n",
      "Epoch 6/10\n",
      "2800/2800 [==============================] - 85s 30ms/step - loss: 0.4028 - digit1_loss: 0.0722 - digit2_loss: 0.1091 - digit3_loss: 0.0960 - digit4_loss: 0.1255 - digit1_acc: 0.9775 - digit2_acc: 0.9657 - digit3_acc: 0.9718 - digit4_acc: 0.9679 - val_loss: 0.8717 - val_digit1_loss: 0.2179 - val_digit2_loss: 0.2819 - val_digit3_loss: 0.2098 - val_digit4_loss: 0.1621 - val_digit1_acc: 0.9514 - val_digit2_acc: 0.9286 - val_digit3_acc: 0.9400 - val_digit4_acc: 0.9543\n",
      "\n",
      "Epoch 00006: saving model to model/06-0.40-0.87.hdf5\n",
      "Epoch 7/10\n",
      "2800/2800 [==============================] - 85s 30ms/step - loss: 0.3469 - digit1_loss: 0.0560 - digit2_loss: 0.0902 - digit3_loss: 0.0941 - digit4_loss: 0.1066 - digit1_acc: 0.9825 - digit2_acc: 0.9732 - digit3_acc: 0.9721 - digit4_acc: 0.9682 - val_loss: 0.7936 - val_digit1_loss: 0.1923 - val_digit2_loss: 0.2415 - val_digit3_loss: 0.2082 - val_digit4_loss: 0.1516 - val_digit1_acc: 0.9600 - val_digit2_acc: 0.9443 - val_digit3_acc: 0.9371 - val_digit4_acc: 0.9529\n",
      "\n",
      "Epoch 00007: saving model to model/07-0.35-0.79.hdf5\n",
      "Epoch 8/10\n",
      "2800/2800 [==============================] - 90s 32ms/step - loss: 0.3056 - digit1_loss: 0.0604 - digit2_loss: 0.0900 - digit3_loss: 0.0664 - digit4_loss: 0.0889 - digit1_acc: 0.9800 - digit2_acc: 0.9693 - digit3_acc: 0.9800 - digit4_acc: 0.9786 - val_loss: 1.0253 - val_digit1_loss: 0.2570 - val_digit2_loss: 0.3100 - val_digit3_loss: 0.2862 - val_digit4_loss: 0.1721 - val_digit1_acc: 0.9329 - val_digit2_acc: 0.9114 - val_digit3_acc: 0.9129 - val_digit4_acc: 0.9429\n",
      "\n",
      "Epoch 00008: saving model to model/08-0.31-1.03.hdf5\n",
      "Epoch 9/10\n",
      "2800/2800 [==============================] - 88s 31ms/step - loss: 0.2840 - digit1_loss: 0.0644 - digit2_loss: 0.0724 - digit3_loss: 0.0597 - digit4_loss: 0.0875 - digit1_acc: 0.9782 - digit2_acc: 0.9789 - digit3_acc: 0.9814 - digit4_acc: 0.9768 - val_loss: 0.7897 - val_digit1_loss: 0.2066 - val_digit2_loss: 0.2290 - val_digit3_loss: 0.2114 - val_digit4_loss: 0.1427 - val_digit1_acc: 0.9514 - val_digit2_acc: 0.9400 - val_digit3_acc: 0.9371 - val_digit4_acc: 0.9557\n",
      "\n",
      "Epoch 00009: saving model to model/09-0.28-0.79.hdf5\n",
      "Epoch 10/10\n",
      "2800/2800 [==============================] - 88s 31ms/step - loss: 0.2216 - digit1_loss: 0.0472 - digit2_loss: 0.0525 - digit3_loss: 0.0484 - digit4_loss: 0.0735 - digit1_acc: 0.9850 - digit2_acc: 0.9811 - digit3_acc: 0.9875 - digit4_acc: 0.9846 - val_loss: 0.7562 - val_digit1_loss: 0.2221 - val_digit2_loss: 0.2047 - val_digit3_loss: 0.2054 - val_digit4_loss: 0.1239 - val_digit1_acc: 0.9529 - val_digit2_acc: 0.9429 - val_digit3_acc: 0.9443 - val_digit4_acc: 0.9614\n",
      "\n",
      "Epoch 00010: saving model to model/10-0.22-0.76.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, validation_split=0.2, batch_size=50, epochs=10, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history, train, validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history(history, 'digit1_acc', 'val_digit1_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
